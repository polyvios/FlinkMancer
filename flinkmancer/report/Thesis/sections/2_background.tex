
\chapter{Background}

In this thesis we are trying to extract features from a given Data set in order to train a Logistic Regression model and predict missing or future links.
The project was created using Java and Apache-Flink. We build the project using Apache Maven. 
 





\section{Feature Extraction}
In machine learning, input data is usually too large to be processed and requires to be transformed into a reduced set of features. Those features are supposed to be informative and non-redundant while also allowing better human interpretations. The process of deciding which Features are going to be used is called feature selection and the whole process is called feature Extraction. The way we extracted features in this work is explained in detail in ``Predicting positive and negative links in online social networks"[3] 
\section{Logistic Regression}
Logistic regression (LR) is a statistical method which finds an equation that predicts an outcome for a binary variable, Y, from one or more response variables, X. The variables can be categorical or continuous. It assumes independence among variables, although the applicability of the method often trumps statistical assumptions. One drawback of LR is that the method cannot produce typicality probabilities. A more detailed approach can be found in ``Research methods in human skeletal biology"[2]

\section{Apache Flink}

Apache Flink is a framework designed to run in cluster environments and perform computations over bound and unbound data streams. 
    \begin{description}
    \item $\bullet$ Unbounded streams have a start but no defined end. They must be continuously processed and it is not possible to wait for all input data to arrive.
    Precise control of time and state enable Flink to run any kind of application on unbounded streams. 

    \item $\bullet$ Bounded streams have a defined start and end. They can be processed by ingesting all data before performing any computations because they are processed by algorithms and data structures that are specifically designed for fixed sized data sets, yielding excellent performance.
    Processing of bounded streams is also known as batch processing.
    \end{description}
    
When deploying an application, Flink identifies the required resources and requests them from the resource manager. In case of a failure, Flink replaces the failed container by requesting new resources. 

Flink maintains a very large application state. It has an asynchronous and incremental check-pointing algorithm which ensures minimal impact on processing latency. 
This guarantees exactly-once state consistency

